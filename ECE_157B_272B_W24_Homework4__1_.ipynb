{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YllyRSiBQftd"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p00TIqOjQfth"
      },
      "source": [
        "\n",
        "# Reinforcement Learning (DQN) Tutorial\n",
        "**Author**: [Adam Paszke](https://github.com/apaszke)\n",
        "            [Mark Towers](https://github.com/pseudo-rnd-thoughts)\n",
        "\n",
        "Heavily edited by [Matthew Dupree](https://github.com/4onen) and Heekyung Lee for UCSB ECE 157B 272B Winter 2025\n",
        "\n",
        "This tutorial shows how to use PyTorch to train a Deep Q Learning (DQN) agent\n",
        "on the CartPole-v1 task from [Gymnasium](https://gymnasium.farama.org).\n",
        "\n",
        "**Task**\n",
        "\n",
        "The agent has to decide between two actions - moving the cart left or\n",
        "right - so that the pole attached to it stays upright. You can find more\n",
        "information about the environment and other more challenging environments at\n",
        "[Gymnasium's website](https://gymnasium.farama.org/environments/classic_control/cart_pole/).\n",
        "\n",
        "**CartPole**\n",
        "\n",
        "As the agent observes the current state of the environment and chooses\n",
        "an action, the environment *transitions* to a new state, and also\n",
        "returns a reward that indicates the consequences of the action. In this\n",
        "task, rewards are +1 for every incremental timestep and the environment\n",
        "terminates if the pole falls over too far or the cart moves more than 2.4\n",
        "units away from center. This means better performing scenarios will run\n",
        "for longer duration, accumulating larger return.\n",
        "\n",
        "The CartPole task is designed so that the inputs to the agent are 4 real\n",
        "values representing the environment state (position, velocity, etc.).\n",
        "We take these 4 inputs without any scaling and pass them through a\n",
        "small fully-connected network with 2 outputs, one for each action.\n",
        "The network is trained to predict the expected value for each action,\n",
        "given the input state. The action with the highest expected value is\n",
        "then chosen.\n",
        "\n",
        "\n",
        "**Packages**\n",
        "\n",
        "First, let's import needed packages. For our environments, we need\n",
        "[gymnasium](https://gymnasium.farama.org/), installed by using `pip`.\n",
        "This is a fork of the original OpenAI Gym project and maintained by\n",
        "the same team since Gym v0.19.\n",
        "\n",
        "In order for the `box2d` environments to install correctly, we\n",
        "first need to install the `swig` package. This is a limitation of\n",
        "the build process for the `box2d` environments, so needs to be\n",
        "run as a separate step.\n",
        "\n",
        "For our model, we'll use the `torch` package, which is the PyTorch\n",
        "machine learning library. Training these simple reinforcement learning\n",
        "environments is quite doable on CPU, as the serial nature of the\n",
        "environments means that we don't get much benefit from GPU parallelism.\n",
        "Thus, a CPU-only installation link for PyTorch is provided, commented\n",
        "out, below.\n",
        "\n",
        "We use `numpy` to manipulate values in multiple places in the code, and\n",
        "plot using the `plotly` library (which requires `pandas` and `nbformat`.)\n",
        "`tqdm` provides nice progress bars for our training loops, and `ipywidgets`\n",
        "allows for a nice increase in interactivity for some cells.\n",
        "\n",
        "Finally, `ffmpeg` and `moviepy` are used to create the videos of the\n",
        "agent's performance in the environment, when the environment is wrapped\n",
        "with the `RecordVideo` wrapper from the `gym.wrappers` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y_Bz9fFCQfti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "613aef3e-03cd-4935-b454-ed011f792f54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting swig\n",
            "  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.9 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/1.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.3.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (5.10.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Requirement already satisfied: gymnasium[box2d,classic_control] in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d,classic_control]) (3.1.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d,classic_control]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d,classic_control])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d,classic_control]) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d,classic_control]) (4.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat) (5.7.2)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.11/dist-packages (from nbformat) (5.7.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat) (0.23.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.1.31)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: box2d-py, ffmpeg\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2379450 sha256=7344919ce68978315b86d999c040bba54251bc1d96b472ecc1edbf7e166f419a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=bf12d5fc078fdd573eddb78dffb33c89693dcbf6c785b0624746eceb2e96f874\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/30/c5/576bdd729f3bc062d62a551be7fefd6ed2f761901568171e4e\n",
            "Successfully built box2d-py ffmpeg\n",
            "Installing collected packages: ffmpeg, box2d-py, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed box2d-py-2.3.5 ffmpeg-1.4 jedi-0.19.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "%pip install swig\n",
        "# %pip install torch --index-url https://download.pytorch.org/whl/cpu\n",
        "%pip install torch \"gymnasium[classic_control,box2d]\" pandas numpy nbformat plotly tqdm moviepy ffmpeg ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quamCIqJQftj"
      },
      "source": [
        "For `moviepy` to work in making recordings of the environment, you will need to have the `ffmpeg` executable installed. If you are running this in Google Colab and encounter issues, run:\n",
        "\n",
        "```bash\n",
        "!apt-get install ffmpeg\n",
        "```\n",
        "\n",
        "in a code cell. If you are running this locally, you can install `ffmpeg` by following the instructions [here](https://ffmpeg.org/download.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5wTOpaXQftj"
      },
      "source": [
        "We'll also use the following from PyTorch:\n",
        "\n",
        "-  neural networks (``torch.nn``)\n",
        "-  optimization (``torch.optim``)\n",
        "-  automatic differentiation (``torch.autograd``)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bNToarxWQftj"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, NamedTuple\n",
        "import math\n",
        "import random\n",
        "from collections import deque\n",
        "from itertools import count\n",
        "\n",
        "from pathlib import Path\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium.wrappers import TimeLimit\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "import numpy as np\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "from tqdm import trange, tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "MAX_ENV_STEPS = 750\n",
        "# TODO\n",
        "GYM_ENV = \"LunarLander-v3\"\n",
        "VIDEOS_DIR = f\"{GYM_ENV}_videos\"\n",
        "env = gym.make(GYM_ENV, render_mode=\"rgb_array\", max_episode_steps=MAX_ENV_STEPS)\n",
        "env = RecordVideo(env, video_folder=VIDEOS_DIR, episode_trigger=lambda episode_id: episode_id < 50 or episode_id % 25 == 0)\n",
        "# if GPU is to be used\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1jtFNp3Qftj"
      },
      "source": [
        "## Replay Memory\n",
        "\n",
        "We'll be using experience replay memory for training our DQN. It stores\n",
        "the transitions that the agent observes, allowing us to reuse this data\n",
        "later. By sampling from it randomly, the transitions that build up a\n",
        "batch are decorrelated. It has been shown that this greatly stabilizes\n",
        "and improves the DQN training procedure.\n",
        "\n",
        "For this, we're going to need two classes:\n",
        "\n",
        "-  ``Transition`` - a named tuple representing a single transition in\n",
        "   our environment. It essentially maps (state, action) pairs\n",
        "   to their (next_state, reward) result, with the state being the\n",
        "   screen difference image as described later on.\n",
        "-  ``ReplayMemory`` - a cyclic buffer of bounded size that holds the\n",
        "   transitions observed recently. It also implements a ``.sample()``\n",
        "   method for selecting a random batch of transitions for training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "PyFbZb8iQftk"
      },
      "outputs": [],
      "source": [
        "class Transition(NamedTuple):\n",
        "    state: np.ndarray\n",
        "    action: int\n",
        "    next_state: np.ndarray\n",
        "    reward: float\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity: int):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9RyCOQHQftk"
      },
      "source": [
        "Now, let's define our model. But first, let's quickly recap what a DQN is.\n",
        "\n",
        "## DQN algorithm\n",
        "\n",
        "Our environment is deterministic, so all equations presented here are\n",
        "also formulated deterministically for the sake of simplicity. In the\n",
        "reinforcement learning literature, they would also contain expectations\n",
        "over stochastic transitions in the environment.\n",
        "\n",
        "Our aim will be to train a policy that tries to maximize the discounted,\n",
        "cumulative reward\n",
        "$R_{t_0} = \\sum_{t=t_0}^{\\infty} \\gamma^{t - t_0} r_t$, where\n",
        "$R_{t_0}$ is also known as the *return*. The discount,\n",
        "$\\gamma$, should be a constant between $0$ and $1$\n",
        "that ensures the sum converges. A lower $\\gamma$ makes\n",
        "rewards from the uncertain far future less important for our agent\n",
        "than the ones in the near future that it can be fairly confident\n",
        "about. It also encourages agents to collect reward closer in time\n",
        "than equivalent rewards that are temporally far away in the future.\n",
        "\n",
        "The main idea behind Q-learning is that if we had a function\n",
        "$Q^*: State \\times Action \\rightarrow \\mathbb{R}$, that could tell\n",
        "us what our return would be, if we were to take an action in a given\n",
        "state, then we could easily construct a policy that maximizes our\n",
        "rewards:\n",
        "\n",
        "\\begin{align}\\pi^*(s) = \\arg\\!\\max_a \\ Q^*(s, a)\\end{align}\n",
        "\n",
        "However, we don't know everything about the world, so we don't have\n",
        "access to $Q^*$. But, since neural networks are universal function\n",
        "approximators, we can simply create one and train it to resemble\n",
        "$Q^*$.\n",
        "\n",
        "For our training update rule, we'll use a fact that every $Q$\n",
        "function for some policy obeys the Bellman equation:\n",
        "\n",
        "\\begin{align}Q^{\\pi}(s, a) = r + \\gamma Q^{\\pi}(s', \\pi(s'))\\end{align}\n",
        "\n",
        "The difference between the two sides of the equality is known as the\n",
        "temporal difference error, $\\delta$:\n",
        "\n",
        "\\begin{align}\\delta = Q(s, a) - (r + \\gamma \\max_a' Q(s', a))\\end{align}\n",
        "\n",
        "To minimize this error, we will use the [Huber\n",
        "loss](https://en.wikipedia.org/wiki/Huber_loss)_. The Huber loss acts\n",
        "like the mean squared error when the error is small, but like the mean\n",
        "absolute error when the error is large - this makes it more robust to\n",
        "outliers when the estimates of $Q$ are very noisy. We calculate\n",
        "this over a batch of transitions, $B$, sampled from the replay\n",
        "memory:\n",
        "\n",
        "\\begin{align}\\mathcal{L} = \\frac{1}{|B|}\\sum_{(s, a, s', r) \\ \\in \\ B} \\mathcal{L}(\\delta)\\end{align}\n",
        "\n",
        "\\begin{align}\\text{where} \\quad \\mathcal{L}(\\delta) = \\begin{cases}\n",
        "     \\frac{1}{2}{\\delta^2}  & \\text{for } |\\delta| \\le 1, \\\\\n",
        "     |\\delta| - \\frac{1}{2} & \\text{otherwise.}\n",
        "   \\end{cases}\\end{align}\n",
        "\n",
        "### Q-network\n",
        "\n",
        "Our model will be a feed forward  neural network that takes in the\n",
        "difference between the current and previous screen patches. It has two\n",
        "outputs, representing $Q(s, \\mathrm{left})$ and\n",
        "$Q(s, \\mathrm{right})$ (where $s$ is the input to the\n",
        "network). In effect, the network is trying to predict the *expected return* of\n",
        "taking each action given the current input.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "WyVrorcoQftk"
      },
      "outputs": [],
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, n_observations: int, n_actions: int):\n",
        "        super(DQN, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_observations, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1.forward(x))\n",
        "        x = F.relu(self.layer2.forward(x))\n",
        "        return self.layer3.forward(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-IpLJOaQftk"
      },
      "source": [
        "## Training\n",
        "\n",
        "### Hyperparameters and utilities\n",
        "This cell instantiates our model and its optimizer, and defines some\n",
        "utilities:\n",
        "\n",
        "-  ``select_action`` - will select an action accordingly to an epsilon\n",
        "   greedy policy. Simply put, we'll sometimes use our model for choosing\n",
        "   the action, and sometimes we'll just sample one uniformly. The\n",
        "   probability of choosing a random action will start at ``EPS_START``\n",
        "   and will decay exponentially towards ``EPS_END``. ``EPS_DECAY``\n",
        "   controls the rate of the decay.\n",
        "-  ``plot_durations`` - a helper for plotting the duration of episodes,\n",
        "   along with an average over the last 100 episodes (the measure used in\n",
        "   the official evaluations). The plot will be underneath the cell\n",
        "   containing the main training loop, and will update after every\n",
        "   episode.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "MPrmA7_2Qftk"
      },
      "outputs": [],
      "source": [
        "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
        "# GAMMA is the discount factor as mentioned in the previous section\n",
        "# EPS_START is the starting value of epsilon\n",
        "# EPS_END is the final value of epsilon\n",
        "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
        "# TAU is the update rate of the target network\n",
        "# LR is the learning rate of the ``AdamW`` optimizer\n",
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.99\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 8000\n",
        "TAU = 0.005\n",
        "LR = 7e-4\n",
        "\n",
        "# Get number of actions from gym action space\n",
        "n_actions: int = int(env.action_space.n)  # type: ignore\n",
        "# Get the number of state observations\n",
        "state, info = env.reset()\n",
        "n_observations: int = len(state)\n",
        "\n",
        "policy_net_decompiled = DQN(n_observations, n_actions).to(device)\n",
        "policy_net: torch.jit.ScriptModule = torch.jit.script(policy_net_decompiled)  # type: ignore\n",
        "target_net_decompiled = DQN(n_observations, n_actions).to(device)\n",
        "target_net: torch.jit.ScriptModule = torch.jit.script(target_net_decompiled)  # type: ignore\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True, capturable=False)\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "\n",
        "def select_action(state: torch.Tensor, steps_done: int):\n",
        "    sample = torch.rand(1, dtype=torch.float16, requires_grad=False)\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(\n",
        "        -1.0 * steps_done / EPS_DECAY\n",
        "    )\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            # t.max(1) will return the largest column value of each row.\n",
        "            # second column on max result is index of where max element was\n",
        "            # found, so we pick action with the larger expected reward.\n",
        "            return policy_net(state).max(1).indices.view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor(\n",
        "            [[env.action_space.sample()]], device=device, dtype=torch.long\n",
        "        )\n",
        "\n",
        "\n",
        "class PlotDurations:\n",
        "    def __init__(self) -> None:\n",
        "        fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=1,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.02,\n",
        "            subplot_titles=(\"Episode Duration\", \"Episode Reward\"),\n",
        "        )\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=[], y=[], mode=\"lines\", name=\"Duration\"), row=1, col=1\n",
        "        )\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=[], y=[], mode=\"lines\", name=\"Reward\"), row=2, col=1\n",
        "        )\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=[],\n",
        "                y=[],\n",
        "                mode=\"lines\",\n",
        "                name=\"Duration (100 episode average)\",\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=[],\n",
        "                y=[],\n",
        "                mode=\"lines\",\n",
        "                name=\"Reward (100 episode average)\",\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "        fig.update_layout(\n",
        "            title=\"Training...\",\n",
        "            showlegend=False,\n",
        "            margin=dict(l=0, r=0, t=30, b=0),\n",
        "        )\n",
        "        fig.update_yaxes(title_text=\"Duration\", row=1, col=1)\n",
        "        fig.update_yaxes(title_text=\"Reward\", row=2, col=1)\n",
        "        fig.update_xaxes(title_text=\"Episode\", row=2, col=1)\n",
        "        self.fig_widget = go.FigureWidget(fig)\n",
        "\n",
        "        try:\n",
        "            import IPython.display as ipdisplay\n",
        "\n",
        "            self.ipdisplay = ipdisplay\n",
        "        except ImportError:\n",
        "            self.ipdisplay = None\n",
        "\n",
        "    def show(self):\n",
        "        self.fig_widget.show()\n",
        "\n",
        "    def update(self, episode_duration: int, episode_reward: float, redisplay: bool=True):\n",
        "        duration_scatter: go.Scatter = self.fig_widget.data[0]  # type: ignore\n",
        "        reward_scatter: go.Scatter = self.fig_widget.data[1]  # type: ignore\n",
        "        episode = len(duration_scatter.x) + 1  # type: ignore\n",
        "        new_episode_axis: Tuple[int] = duration_scatter.x + (episode,)  # type: ignore\n",
        "        new_duration_axis: Tuple[int] = duration_scatter.y + (episode_duration,)  # type: ignore\n",
        "        new_reward_axis: Tuple[int] = reward_scatter.y + (episode_reward,)  # type: ignore\n",
        "        with self.fig_widget.batch_update():\n",
        "            duration_scatter.x = new_episode_axis\n",
        "            reward_scatter.x = new_episode_axis\n",
        "            duration_scatter.y = new_duration_axis\n",
        "            reward_scatter.y = new_reward_axis\n",
        "\n",
        "        if redisplay and (self.ipdisplay is not None):\n",
        "            self.ipdisplay.clear_output(wait=True)\n",
        "            self.fig_widget.show()\n",
        "\n",
        "    def finish(self, title: str = \"Results\"):\n",
        "        self.fig_widget.update_layout(title=title)\n",
        "\n",
        "\n",
        "plot_durations = PlotDurations()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWmfXG1TQftl"
      },
      "source": [
        "### Training loop\n",
        "\n",
        "Finally, the code for training our model.\n",
        "\n",
        "Here, you can find an ``optimize_model`` function that performs a\n",
        "single step of the optimization. It first samples a batch, concatenates\n",
        "all the tensors into a single one, computes $Q(s_t, a_t)$ and\n",
        "$V(s_{t+1}) = \\max_a Q(s_{t+1}, a)$, and combines them into our\n",
        "loss. By definition we set $V(s) = 0$ if $s$ is a terminal\n",
        "state. We also use a target network to compute $V(s_{t+1})$ for\n",
        "added stability. The target network is updated at every step with a\n",
        "[soft update](https://arxiv.org/pdf/1509.02971.pdf) controlled by\n",
        "the hyperparameter ``TAU``, which was previously defined.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "oFNGMKiZQftl"
      },
      "outputs": [],
      "source": [
        "@torch.compile(fullgraph=True)\n",
        "def do_optimization_inner(state_batch, action_batch, reward_batch, non_final_next_states, non_final_mask):\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken. These are the actions which would've been taken\n",
        "    # for each batch state according to policy_net\n",
        "    state_action_values = policy_net_decompiled(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    # Expected values of actions for non_final_next_states are computed based\n",
        "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
        "    # This is merged based on the mask, such that we'll have either the expected\n",
        "    # state value or 0 in case the state was final.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    with torch.no_grad():\n",
        "        next_state_values[non_final_mask] = target_net_decompiled(non_final_next_states).max(1).values\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    loss = nn.functional.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    return loss\n",
        "\n",
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). This converts batch-array of Transitions\n",
        "    # to Transition of batch-arrays.\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    # (a final state would've been the one after which simulation ended)\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    loss = do_optimization_inner(state_batch, action_batch, reward_batch, non_final_next_states, non_final_mask)\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    # In-place gradient clipping\n",
        "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "WvBXtCn4Qftl"
      },
      "outputs": [],
      "source": [
        "@torch.compile(fullgraph=True)\n",
        "@torch.no_grad\n",
        "def policy_net_update():\n",
        "    # Soft update of the target network's weights\n",
        "    # θ′ ← τ θ + (1 −τ )θ′\n",
        "    for target_net_param, policy_net_param in zip(target_net_decompiled.parameters(), policy_net_decompiled.parameters()):\n",
        "        torch.Tensor.lerp_(target_net_param, policy_net_param, TAU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90Wba7DeQftm"
      },
      "source": [
        "Below, you can find the main training loop. At the beginning we reset\n",
        "the environment and obtain the initial ``state`` Tensor. Then, we sample\n",
        "an action, execute it, observe the next state and the reward (always\n",
        "1), and optimize our model once. When the episode ends (our model\n",
        "fails), we restart the loop.\n",
        "\n",
        "Below, `num_episodes` is set to 600. Training RL agents can be a\n",
        "noisy process, so restarting training can produce better results\n",
        "if convergence is not observed.\n",
        "\n",
        "**== EPILEPSY WARNING: The training graph in the cell below may flash repeatedly during training in Google Colab. ==**\n",
        "\n",
        "If you are sensitive to flashing lights, set `DISPLAY_GRAPH_DURING_TRAINING` to `False` in the cell below,\n",
        "and the graph will only be displayed at the end of training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "qrupvuveQftm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a0fab13-c488-4b3c-92c2-5c116bf8dc8a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"b1ca3ae1-d9c7-408d-96bf-8b53831d6443\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b1ca3ae1-d9c7-408d-96bf-8b53831d6443\")) {                    Plotly.newPlot(                        \"b1ca3ae1-d9c7-408d-96bf-8b53831d6443\",                        [{\"mode\":\"lines\",\"name\":\"Duration\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"xaxis\":\"x\",\"y\":[74,118,97,92,69,97,148,152,133,91,73,88,94,68,102,71,95,92,88,75,124,116,195,136,151,133,147,96,195,81,95,105,87,92,123,128,196,183,163,445,108,234,352,172,205,749,749,749,749,169,137,749,749,141,749,749,749,749,749,749,749,749,749,749,749,749,749,749,749,729,749,526,749,749,749,619,749,749,749,749,749,749,749,749,620,749,562,749,749,749,411,749,749,749,749,749,749,749,377,295,714,422,749,749,749,749,663,749,749,605,401,308,749,699,616,714,749,152,304,749,433,440,473,480,644,451,420,455,389,346,678,336,519,749,370,356,240,646,749,277,387,339,446,216,393,378,286,749,592,448,703,749,749,749,749,255,343,749,581,501,749,318,132,367,361,687,690,287,749,522,749,197,413,701,246,107,302,189,408,299,192,210,366,177,355,193,147,749,172,150,535,258,177,371,270,259,749,419,393,240,315,259,599,576,590,501,410,505,319,288,644,136,210,380,145,266,267,222,608,363,305,343,244,363,363,634,422,380,302,199,96,360,240,352,221,558,328,269,614,333,370,293,449,485,273,336,274,407,314,415,749,205,171,218,256,228,236,305,283,241,179,125,324,214,237,210,277,328,236,274,388,301,282,276,337,702,271,254,215,203,442,269,339,272,225,422,287,327,173,294,206,304,261,293,269,240,749,270,224,273,302,359,221,215,456,263,260,345,254,260,336,286,255,195,364,348,261,273,180,220,299,290,243,434,275,216,425,366,454,216,247,111,309,120,275,340,215,312,141,131,367,404,244,295,303,307,470,252,282,226,106,420,731,113,261,224,355,241,350,353,314,274,312,80,276,289,362,255,308,110,107,749,283,267,252,309,468,440,497,749,749,289,470,749,749,749,603,561,749,749,386,749,737,305,749,333,354,749,439,749,699,501,582,372,452,501,71,395,433,119,738,749,164,749,749,749,749,622,448,749,749,749,598,749,692,749,464,749,717,749,749,749,749,749,749,749,565,711,354,749,254,749,749,749,155,657,332,749,284,415,200,103,749,375,255,243,587,530,334,417,393,423,749,335,343,96,380,315,570,369,257,424,359,411,382,284,269,236,261,292,303,358,367,360,256,343,299,422,365,146,299,328,288,452,419,409,290,291,337,496,401,299,137,416,280,286,276,499,323,286,305,280,264,395,214,272,336,536,749,339,388,371,385,749,320,352,242,714,576,249,248,368,136,156,216,132,223,228,230,374,256,285,174,749,265,499,242,303,387,394,362,384,372,287,308,296,581,422,400,719,481,257,487,349,562,326,350,476,749,444,432,736,521,501,416,381,491,544,749,749,261,235,309,404,742,283,471,90,260,442,499,385,248,252,327,237,222,499,283,99],\"yaxis\":\"y\",\"type\":\"scatter\",\"uid\":\"8c140d2c-e71b-4d34-a7c8-0c6e1d2541dc\"},{\"mode\":\"lines\",\"name\":\"Reward\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"xaxis\":\"x2\",\"y\":[-135.58525822599287,-172.78634608373045,-242.64700120675323,-61.29880864846304,-43.173147699082136,-187.88110265741778,-272.0665440477042,-54.2320356515127,-353.43688379065804,-107.31132939926638,-155.1026170798979,-294.3230726259206,-87.86306642250575,-93.8534526002658,-148.53576576649175,-144.14582351483827,-113.37748200970844,-105.72429208269948,-43.9359025233404,-120.41898989129925,-72.1610630891582,-111.65754836754098,-26.3485035618004,-105.74537817895151,-52.278889502262295,-56.718981387136445,-89.54580670747525,-55.87005935887109,-85.49695791530519,-44.896455432926004,-118.43539399584868,-57.115410109594,-27.242534013488168,-110.43238610448857,-156.297381444706,-51.032744479233685,-26.825889471373486,-31.604900694280545,-22.53618955997092,-35.87433104918901,-31.584501495460316,21.27965098588706,7.783331457170945,4.7272863417042,-140.59371543732675,64.66469197162564,60.577467363460215,32.89821062948623,82.25999774747578,0.7759948792274258,21.09114957744616,47.77119386293992,-5.652827249730376,-22.05733395979864,34.694228940920965,15.851176167777162,-11.359518266562048,33.663836861488754,43.88229834080267,-24.02726589481603,21.02499581015743,69.89239042316854,43.37913210808704,71.26309944691792,9.242859165770462,51.892007900612235,55.48854503361177,13.307416551500644,68.35927238051667,247.38281636984993,87.37060425541112,255.42439801016607,61.37582211829485,74.74441293909217,39.29486320665931,228.77185834460158,38.29969084368735,26.26822051976632,-3.1780539956688996,7.300568827902604,16.882097013482063,58.288057238812705,35.95605269198176,27.24337380914315,187.34876186238586,40.164162549142105,249.5388376747684,64.04377650452992,9.891712263312147,85.94493641491417,221.57277750789407,11.434243978675099,37.76349896135045,22.53858332887733,71.73188245973365,47.36583312825063,74.22399841937705,22.458198707834605,241.50998190129425,238.25307973832992,162.55178440956033,164.3149697064728,49.90118672729273,120.7249703171114,44.27448880738752,58.274386924168184,202.9840064593969,23.24313292283473,57.867552104336816,203.32533299359275,227.87176901544038,235.8993053330333,65.90568985521705,196.56650403216628,222.28703713622772,150.1040102715052,31.0310280172145,-314.2663653840606,255.1856766785702,-11.720698565191933,233.27176956923302,240.8978809497844,262.9142085232778,235.2325426861172,273.5253919445632,232.40064883052798,236.06796964044918,279.2480239120688,219.63306169316627,239.27496631942157,188.86700561738553,226.86845024210092,235.5159774346701,176.9246823618042,209.91725006567088,270.26891298678396,269.7685875846087,257.88501884197484,116.74796517473537,268.5151210576453,266.8966957168422,264.04653871284114,245.8718219287821,245.82850418879278,233.7958301225222,253.33100826561446,271.33102932458394,171.60080621799224,274.3352588417823,238.31864777176588,226.06117013527455,133.75666390900668,118.95777168326039,124.79828891826742,114.22872877167907,284.22712626476664,257.7450179636023,101.58094191630045,234.55340621310177,234.73916856649407,156.1033644981144,279.0054096275568,32.463016055030124,223.18465525954173,288.9024503533908,166.88067148045732,192.36942011611922,237.01018976598698,150.4554414480191,239.48489553219383,162.5450819675193,305.73967004079145,250.45581512864064,219.34300017792145,203.70269183933226,21.169346935925148,271.0917670623021,250.43582077782472,226.67337091956603,261.8676897847957,278.1857551057436,236.037763369144,249.26679044440183,254.8925831445835,261.6725590462866,258.8844336519397,277.5963937346852,141.73767785915422,246.27171532687314,254.46471514083785,260.6897112669435,261.63090004284925,279.5779686520251,271.9300991768267,283.8687960050878,264.2399811149556,130.27903456289604,236.9538146797195,266.9556798673326,257.42810521038473,253.16341049411892,262.1112168029697,245.13438067749402,233.61459497958614,203.7013899459507,269.4297378700441,214.6357059589772,210.97444700939124,256.1277249550592,261.1784573603802,181.4394726870314,9.293203125496177,288.10212330554634,259.9434798971133,32.263488350762174,279.4489887944357,283.7441216520652,285.9227426254045,248.74079124094007,222.43219047436395,243.94217658270165,269.63954781380926,259.8288316647157,231.55839794875948,210.09018148999166,202.64079554562335,234.03623570215967,261.3478257524258,284.8852695310204,274.50318884953924,-33.184151276384796,289.07785740292616,242.44150476506678,259.5818855179732,274.28406117050355,200.06340322323803,253.96591085570782,251.27219323538768,224.7449732719012,268.8428243022177,241.38239137465692,246.48360149821582,242.43859837117478,239.87429752520228,252.51865892922774,272.2129575392106,220.3350797616493,270.26516511506605,264.198962891269,253.96173833283015,134.67330129195005,245.84812189797015,274.78020090889595,296.5060183855853,253.53295703076003,249.0951425966486,280.9296424975919,254.88230697596663,260.9677851820623,251.59075388349893,289.99331268895656,82.39090142735918,277.1397961759558,261.8624754665787,297.1928225075611,299.3680987577238,263.7375159206747,267.72758791372235,260.3282833817042,261.84265720563957,277.38145725296613,270.82792077285774,256.0665416107429,238.52107874550077,294.88022264998426,281.69144319900624,299.23896270928947,268.5072503253337,261.5851906745389,264.1819673647244,278.45137184847863,248.22009288348733,254.72034844069785,287.6760860167434,250.92281534081755,243.90186405909296,273.4756718997833,252.3860674161042,264.5773036751018,281.75544431286767,270.4610191702213,266.42008645172984,243.8449682999579,296.04480729791464,266.594082443329,245.99942661131476,165.53439239044437,289.2604206092002,271.27437911346885,280.68628035686163,263.1458012566135,227.63242634605132,314.46399642910444,238.56211778455398,233.68660036371062,256.55493353151974,249.9557111429989,248.75651786429694,258.921182424477,271.2004479244108,270.2989214591996,260.03439178440635,277.9706236067235,271.21942141132746,244.42005522339326,282.9577686719498,285.7145883086995,255.40681561649717,260.93160402777755,268.9908443604877,270.6323526770882,298.6253742761819,259.32935244273256,287.7331178615935,286.65667055485244,291.5426322789187,243.0880513338795,239.31161937940539,257.74632812686514,272.9161831775899,261.1041829922892,24.893393215352873,290.3479003777325,15.370621489100898,233.34655409761328,287.60265177794923,298.34565079193897,258.56442823173643,27.57622240452116,16.349068767679256,269.95856814896536,248.70665903820998,239.65341549769047,290.6700857743482,249.74101335718157,254.7778200528557,208.9789860701975,241.28306218444095,250.16277036663166,312.09291103110485,-26.195496332303264,236.75134983701665,263.5446933711024,-16.04455038731416,233.93521094914942,270.36106035264015,244.17314927091837,241.86363426898632,273.9234386827861,267.77713141132745,246.3666587485191,308.14429086662255,275.65474923657894,-24.54306003929284,243.81447915965214,256.4918146747301,244.4245702533606,237.91460870642777,288.69570938949107,-51.63706694330732,-52.97044101303638,155.70404193206323,287.41850628141935,272.94413432719875,257.08787908900683,231.994081030161,277.9023741300522,286.17304597264405,234.19589392071637,-0.13140887355452358,150.3952895844843,256.42302033623946,267.99450773437707,43.511545698666396,15.855356243563474,15.115158126464808,204.97792522408898,191.4136765883196,4.2582294867201185,36.65018580052937,24.770315001225015,44.26893945439822,267.34491271314664,266.4769234647465,44.357654409167715,247.3355583270146,265.1166329496956,40.238524133285324,268.1086291643273,54.19584283180064,182.8490406503605,214.4313427079893,226.22658859424638,287.1500660486589,237.0924471399447,231.02539027593537,-27.418108783688126,215.17775389402328,244.24357722319988,-227.90255814722343,194.55264230360532,62.06141251381494,295.52341570882214,78.14912951831437,34.110755416144706,65.1201027931085,72.89906753719733,212.53079211948096,240.95249654340287,20.42354729444176,41.643431389009834,34.59476877027083,256.4300534769527,4.058955127339974,198.28704404628326,46.47504949608945,244.1510473450279,39.661217841926636,162.76435156388885,56.364610653713854,38.620179407174085,87.23379615199438,59.31212467356969,21.417780723578918,22.392729044832326,44.263662688018584,222.37677120307833,194.5946014981866,262.886958081774,65.63518722319318,267.00570910632547,64.69546083629223,73.16745161747204,50.779039466375544,47.93017203395365,206.70228313715856,263.2191801758506,96.9241944058527,268.34624486062773,255.10241553690415,263.9968590302867,51.75153874698509,47.66366937207345,218.7043161019111,280.64481881652927,275.48575350217175,230.43516403968192,236.80596087285312,237.55514716974972,212.8233144927703,235.526837256836,245.82038216941902,1.5574742944762239,283.0365412318406,232.2334953715122,-43.729927145651445,287.82635572379104,242.34563907326458,269.9017468207603,237.97824663878092,257.3423614482721,248.90608255731513,229.6109442689282,259.75658696840134,240.08793589507457,233.39798627740132,270.26441975038415,287.13940158624575,245.0319708028367,242.86526428060662,251.56525459404477,252.52601198026468,210.54314416744614,243.39509602613265,248.3731457035674,263.77129960644504,240.3280807725745,232.8371301990246,257.23033759783436,-15.203526115322163,214.648595782145,274.1237963257365,235.6932915486557,275.05974017841595,261.5568151693212,227.528691849125,245.86476197221938,255.656397427027,267.02109489010155,283.77534992335507,245.25924893430695,241.4352403999256,26.19039091503609,260.90790471644004,269.19626221380554,261.9782112770413,234.21053555777496,286.69137958448766,247.39232222830464,257.86622785138684,248.0038497126168,238.03070346393375,254.08006538175897,289.83516740009264,270.56529690289995,242.09247030300784,221.65756897349354,191.39374016075055,103.22635941871286,267.40153518140744,231.40828940476413,226.6165434102184,247.6732168470807,29.287790266188427,270.80049574415773,268.27724886330964,257.9338129554527,223.14442494561968,211.76885330459245,45.14598236207007,280.3631184528829,250.4626277525997,31.580337049517908,-6.524800951823295,19.635503475004256,1.530161350349644,253.6541117198244,237.1456122459112,38.70769793457984,202.60181266660913,227.79501242988906,252.8140308762786,8.84759129745325,97.10504592874307,277.5328684898525,216.32950376160198,234.4460039742691,243.76367759826678,255.2744599990884,274.132113132674,233.53000078378656,233.21078602698515,260.1506554585196,246.07479721998067,262.27678195286063,281.8497211586383,273.4532591846613,247.47526855239565,226.44135336962933,220.85876392371227,229.3521527764896,282.26048002704533,267.7252276490524,270.13651613208606,214.26419685271622,253.4840355254882,244.26717886134196,262.30407606015024,118.25198422972929,207.17571967400065,268.56881901626997,227.69314769001093,216.70420822548044,235.25021258671168,242.07366368482406,240.32647026512228,236.76114882163733,227.4622512465046,92.81921418385895,156.7159533743273,251.9954250724028,276.62341948962137,258.6716471791931,219.58873430353992,252.37404075093704,271.44400516131986,222.4154842558857,-23.586118914031303,261.74270968423224,253.95130328963208,229.76872546553093,286.7311761703257,235.1967254701803,274.4683417257426,249.93714483745373,250.25722270683906,264.0968463911338,205.3542136063507,251.81855389577805,-5.4403901089242765],\"yaxis\":\"y2\",\"type\":\"scatter\",\"uid\":\"33cedb7c-5f52-4da9-bf47-73a199f8aab1\"},{\"mode\":\"lines\",\"name\":\"Duration (100 episode average)\",\"x\":[],\"xaxis\":\"x\",\"y\":[],\"yaxis\":\"y\",\"type\":\"scatter\",\"uid\":\"b689e1f7-c6cd-4926-9640-0f35c6892b54\"},{\"mode\":\"lines\",\"name\":\"Reward (100 episode average)\",\"x\":[],\"xaxis\":\"x2\",\"y\":[],\"yaxis\":\"y2\",\"type\":\"scatter\",\"uid\":\"bff01419-a566-4fcb-be2b-0019dbe5b207\"}],                        {\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Episode Duration\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Episode Reward\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.49,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":30},\"showlegend\":false,\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Training...\"},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"matches\":\"x2\",\"showticklabels\":false},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.51,1.0],\"title\":{\"text\":\"Duration\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Episode\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.49],\"title\":{\"text\":\"Reward\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b1ca3ae1-d9c7-408d-96bf-8b53831d6443');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 600/600 [26:34<00:00,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"cbd222aa-9651-4204-b4d5-4d49ddcef6f4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cbd222aa-9651-4204-b4d5-4d49ddcef6f4\")) {                    Plotly.newPlot(                        \"cbd222aa-9651-4204-b4d5-4d49ddcef6f4\",                        [{\"mode\":\"lines\",\"name\":\"Duration\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"xaxis\":\"x\",\"y\":[74,118,97,92,69,97,148,152,133,91,73,88,94,68,102,71,95,92,88,75,124,116,195,136,151,133,147,96,195,81,95,105,87,92,123,128,196,183,163,445,108,234,352,172,205,749,749,749,749,169,137,749,749,141,749,749,749,749,749,749,749,749,749,749,749,749,749,749,749,729,749,526,749,749,749,619,749,749,749,749,749,749,749,749,620,749,562,749,749,749,411,749,749,749,749,749,749,749,377,295,714,422,749,749,749,749,663,749,749,605,401,308,749,699,616,714,749,152,304,749,433,440,473,480,644,451,420,455,389,346,678,336,519,749,370,356,240,646,749,277,387,339,446,216,393,378,286,749,592,448,703,749,749,749,749,255,343,749,581,501,749,318,132,367,361,687,690,287,749,522,749,197,413,701,246,107,302,189,408,299,192,210,366,177,355,193,147,749,172,150,535,258,177,371,270,259,749,419,393,240,315,259,599,576,590,501,410,505,319,288,644,136,210,380,145,266,267,222,608,363,305,343,244,363,363,634,422,380,302,199,96,360,240,352,221,558,328,269,614,333,370,293,449,485,273,336,274,407,314,415,749,205,171,218,256,228,236,305,283,241,179,125,324,214,237,210,277,328,236,274,388,301,282,276,337,702,271,254,215,203,442,269,339,272,225,422,287,327,173,294,206,304,261,293,269,240,749,270,224,273,302,359,221,215,456,263,260,345,254,260,336,286,255,195,364,348,261,273,180,220,299,290,243,434,275,216,425,366,454,216,247,111,309,120,275,340,215,312,141,131,367,404,244,295,303,307,470,252,282,226,106,420,731,113,261,224,355,241,350,353,314,274,312,80,276,289,362,255,308,110,107,749,283,267,252,309,468,440,497,749,749,289,470,749,749,749,603,561,749,749,386,749,737,305,749,333,354,749,439,749,699,501,582,372,452,501,71,395,433,119,738,749,164,749,749,749,749,622,448,749,749,749,598,749,692,749,464,749,717,749,749,749,749,749,749,749,565,711,354,749,254,749,749,749,155,657,332,749,284,415,200,103,749,375,255,243,587,530,334,417,393,423,749,335,343,96,380,315,570,369,257,424,359,411,382,284,269,236,261,292,303,358,367,360,256,343,299,422,365,146,299,328,288,452,419,409,290,291,337,496,401,299,137,416,280,286,276,499,323,286,305,280,264,395,214,272,336,536,749,339,388,371,385,749,320,352,242,714,576,249,248,368,136,156,216,132,223,228,230,374,256,285,174,749,265,499,242,303,387,394,362,384,372,287,308,296,581,422,400,719,481,257,487,349,562,326,350,476,749,444,432,736,521,501,416,381,491,544,749,749,261,235,309,404,742,283,471,90,260,442,499,385,248,252,327,237,222,499,283,99],\"yaxis\":\"y\",\"type\":\"scatter\",\"uid\":\"8c140d2c-e71b-4d34-a7c8-0c6e1d2541dc\"},{\"mode\":\"lines\",\"name\":\"Reward\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600],\"xaxis\":\"x2\",\"y\":[-135.58525822599287,-172.78634608373045,-242.64700120675323,-61.29880864846304,-43.173147699082136,-187.88110265741778,-272.0665440477042,-54.2320356515127,-353.43688379065804,-107.31132939926638,-155.1026170798979,-294.3230726259206,-87.86306642250575,-93.8534526002658,-148.53576576649175,-144.14582351483827,-113.37748200970844,-105.72429208269948,-43.9359025233404,-120.41898989129925,-72.1610630891582,-111.65754836754098,-26.3485035618004,-105.74537817895151,-52.278889502262295,-56.718981387136445,-89.54580670747525,-55.87005935887109,-85.49695791530519,-44.896455432926004,-118.43539399584868,-57.115410109594,-27.242534013488168,-110.43238610448857,-156.297381444706,-51.032744479233685,-26.825889471373486,-31.604900694280545,-22.53618955997092,-35.87433104918901,-31.584501495460316,21.27965098588706,7.783331457170945,4.7272863417042,-140.59371543732675,64.66469197162564,60.577467363460215,32.89821062948623,82.25999774747578,0.7759948792274258,21.09114957744616,47.77119386293992,-5.652827249730376,-22.05733395979864,34.694228940920965,15.851176167777162,-11.359518266562048,33.663836861488754,43.88229834080267,-24.02726589481603,21.02499581015743,69.89239042316854,43.37913210808704,71.26309944691792,9.242859165770462,51.892007900612235,55.48854503361177,13.307416551500644,68.35927238051667,247.38281636984993,87.37060425541112,255.42439801016607,61.37582211829485,74.74441293909217,39.29486320665931,228.77185834460158,38.29969084368735,26.26822051976632,-3.1780539956688996,7.300568827902604,16.882097013482063,58.288057238812705,35.95605269198176,27.24337380914315,187.34876186238586,40.164162549142105,249.5388376747684,64.04377650452992,9.891712263312147,85.94493641491417,221.57277750789407,11.434243978675099,37.76349896135045,22.53858332887733,71.73188245973365,47.36583312825063,74.22399841937705,22.458198707834605,241.50998190129425,238.25307973832992,162.55178440956033,164.3149697064728,49.90118672729273,120.7249703171114,44.27448880738752,58.274386924168184,202.9840064593969,23.24313292283473,57.867552104336816,203.32533299359275,227.87176901544038,235.8993053330333,65.90568985521705,196.56650403216628,222.28703713622772,150.1040102715052,31.0310280172145,-314.2663653840606,255.1856766785702,-11.720698565191933,233.27176956923302,240.8978809497844,262.9142085232778,235.2325426861172,273.5253919445632,232.40064883052798,236.06796964044918,279.2480239120688,219.63306169316627,239.27496631942157,188.86700561738553,226.86845024210092,235.5159774346701,176.9246823618042,209.91725006567088,270.26891298678396,269.7685875846087,257.88501884197484,116.74796517473537,268.5151210576453,266.8966957168422,264.04653871284114,245.8718219287821,245.82850418879278,233.7958301225222,253.33100826561446,271.33102932458394,171.60080621799224,274.3352588417823,238.31864777176588,226.06117013527455,133.75666390900668,118.95777168326039,124.79828891826742,114.22872877167907,284.22712626476664,257.7450179636023,101.58094191630045,234.55340621310177,234.73916856649407,156.1033644981144,279.0054096275568,32.463016055030124,223.18465525954173,288.9024503533908,166.88067148045732,192.36942011611922,237.01018976598698,150.4554414480191,239.48489553219383,162.5450819675193,305.73967004079145,250.45581512864064,219.34300017792145,203.70269183933226,21.169346935925148,271.0917670623021,250.43582077782472,226.67337091956603,261.8676897847957,278.1857551057436,236.037763369144,249.26679044440183,254.8925831445835,261.6725590462866,258.8844336519397,277.5963937346852,141.73767785915422,246.27171532687314,254.46471514083785,260.6897112669435,261.63090004284925,279.5779686520251,271.9300991768267,283.8687960050878,264.2399811149556,130.27903456289604,236.9538146797195,266.9556798673326,257.42810521038473,253.16341049411892,262.1112168029697,245.13438067749402,233.61459497958614,203.7013899459507,269.4297378700441,214.6357059589772,210.97444700939124,256.1277249550592,261.1784573603802,181.4394726870314,9.293203125496177,288.10212330554634,259.9434798971133,32.263488350762174,279.4489887944357,283.7441216520652,285.9227426254045,248.74079124094007,222.43219047436395,243.94217658270165,269.63954781380926,259.8288316647157,231.55839794875948,210.09018148999166,202.64079554562335,234.03623570215967,261.3478257524258,284.8852695310204,274.50318884953924,-33.184151276384796,289.07785740292616,242.44150476506678,259.5818855179732,274.28406117050355,200.06340322323803,253.96591085570782,251.27219323538768,224.7449732719012,268.8428243022177,241.38239137465692,246.48360149821582,242.43859837117478,239.87429752520228,252.51865892922774,272.2129575392106,220.3350797616493,270.26516511506605,264.198962891269,253.96173833283015,134.67330129195005,245.84812189797015,274.78020090889595,296.5060183855853,253.53295703076003,249.0951425966486,280.9296424975919,254.88230697596663,260.9677851820623,251.59075388349893,289.99331268895656,82.39090142735918,277.1397961759558,261.8624754665787,297.1928225075611,299.3680987577238,263.7375159206747,267.72758791372235,260.3282833817042,261.84265720563957,277.38145725296613,270.82792077285774,256.0665416107429,238.52107874550077,294.88022264998426,281.69144319900624,299.23896270928947,268.5072503253337,261.5851906745389,264.1819673647244,278.45137184847863,248.22009288348733,254.72034844069785,287.6760860167434,250.92281534081755,243.90186405909296,273.4756718997833,252.3860674161042,264.5773036751018,281.75544431286767,270.4610191702213,266.42008645172984,243.8449682999579,296.04480729791464,266.594082443329,245.99942661131476,165.53439239044437,289.2604206092002,271.27437911346885,280.68628035686163,263.1458012566135,227.63242634605132,314.46399642910444,238.56211778455398,233.68660036371062,256.55493353151974,249.9557111429989,248.75651786429694,258.921182424477,271.2004479244108,270.2989214591996,260.03439178440635,277.9706236067235,271.21942141132746,244.42005522339326,282.9577686719498,285.7145883086995,255.40681561649717,260.93160402777755,268.9908443604877,270.6323526770882,298.6253742761819,259.32935244273256,287.7331178615935,286.65667055485244,291.5426322789187,243.0880513338795,239.31161937940539,257.74632812686514,272.9161831775899,261.1041829922892,24.893393215352873,290.3479003777325,15.370621489100898,233.34655409761328,287.60265177794923,298.34565079193897,258.56442823173643,27.57622240452116,16.349068767679256,269.95856814896536,248.70665903820998,239.65341549769047,290.6700857743482,249.74101335718157,254.7778200528557,208.9789860701975,241.28306218444095,250.16277036663166,312.09291103110485,-26.195496332303264,236.75134983701665,263.5446933711024,-16.04455038731416,233.93521094914942,270.36106035264015,244.17314927091837,241.86363426898632,273.9234386827861,267.77713141132745,246.3666587485191,308.14429086662255,275.65474923657894,-24.54306003929284,243.81447915965214,256.4918146747301,244.4245702533606,237.91460870642777,288.69570938949107,-51.63706694330732,-52.97044101303638,155.70404193206323,287.41850628141935,272.94413432719875,257.08787908900683,231.994081030161,277.9023741300522,286.17304597264405,234.19589392071637,-0.13140887355452358,150.3952895844843,256.42302033623946,267.99450773437707,43.511545698666396,15.855356243563474,15.115158126464808,204.97792522408898,191.4136765883196,4.2582294867201185,36.65018580052937,24.770315001225015,44.26893945439822,267.34491271314664,266.4769234647465,44.357654409167715,247.3355583270146,265.1166329496956,40.238524133285324,268.1086291643273,54.19584283180064,182.8490406503605,214.4313427079893,226.22658859424638,287.1500660486589,237.0924471399447,231.02539027593537,-27.418108783688126,215.17775389402328,244.24357722319988,-227.90255814722343,194.55264230360532,62.06141251381494,295.52341570882214,78.14912951831437,34.110755416144706,65.1201027931085,72.89906753719733,212.53079211948096,240.95249654340287,20.42354729444176,41.643431389009834,34.59476877027083,256.4300534769527,4.058955127339974,198.28704404628326,46.47504949608945,244.1510473450279,39.661217841926636,162.76435156388885,56.364610653713854,38.620179407174085,87.23379615199438,59.31212467356969,21.417780723578918,22.392729044832326,44.263662688018584,222.37677120307833,194.5946014981866,262.886958081774,65.63518722319318,267.00570910632547,64.69546083629223,73.16745161747204,50.779039466375544,47.93017203395365,206.70228313715856,263.2191801758506,96.9241944058527,268.34624486062773,255.10241553690415,263.9968590302867,51.75153874698509,47.66366937207345,218.7043161019111,280.64481881652927,275.48575350217175,230.43516403968192,236.80596087285312,237.55514716974972,212.8233144927703,235.526837256836,245.82038216941902,1.5574742944762239,283.0365412318406,232.2334953715122,-43.729927145651445,287.82635572379104,242.34563907326458,269.9017468207603,237.97824663878092,257.3423614482721,248.90608255731513,229.6109442689282,259.75658696840134,240.08793589507457,233.39798627740132,270.26441975038415,287.13940158624575,245.0319708028367,242.86526428060662,251.56525459404477,252.52601198026468,210.54314416744614,243.39509602613265,248.3731457035674,263.77129960644504,240.3280807725745,232.8371301990246,257.23033759783436,-15.203526115322163,214.648595782145,274.1237963257365,235.6932915486557,275.05974017841595,261.5568151693212,227.528691849125,245.86476197221938,255.656397427027,267.02109489010155,283.77534992335507,245.25924893430695,241.4352403999256,26.19039091503609,260.90790471644004,269.19626221380554,261.9782112770413,234.21053555777496,286.69137958448766,247.39232222830464,257.86622785138684,248.0038497126168,238.03070346393375,254.08006538175897,289.83516740009264,270.56529690289995,242.09247030300784,221.65756897349354,191.39374016075055,103.22635941871286,267.40153518140744,231.40828940476413,226.6165434102184,247.6732168470807,29.287790266188427,270.80049574415773,268.27724886330964,257.9338129554527,223.14442494561968,211.76885330459245,45.14598236207007,280.3631184528829,250.4626277525997,31.580337049517908,-6.524800951823295,19.635503475004256,1.530161350349644,253.6541117198244,237.1456122459112,38.70769793457984,202.60181266660913,227.79501242988906,252.8140308762786,8.84759129745325,97.10504592874307,277.5328684898525,216.32950376160198,234.4460039742691,243.76367759826678,255.2744599990884,274.132113132674,233.53000078378656,233.21078602698515,260.1506554585196,246.07479721998067,262.27678195286063,281.8497211586383,273.4532591846613,247.47526855239565,226.44135336962933,220.85876392371227,229.3521527764896,282.26048002704533,267.7252276490524,270.13651613208606,214.26419685271622,253.4840355254882,244.26717886134196,262.30407606015024,118.25198422972929,207.17571967400065,268.56881901626997,227.69314769001093,216.70420822548044,235.25021258671168,242.07366368482406,240.32647026512228,236.76114882163733,227.4622512465046,92.81921418385895,156.7159533743273,251.9954250724028,276.62341948962137,258.6716471791931,219.58873430353992,252.37404075093704,271.44400516131986,222.4154842558857,-23.586118914031303,261.74270968423224,253.95130328963208,229.76872546553093,286.7311761703257,235.1967254701803,274.4683417257426,249.93714483745373,250.25722270683906,264.0968463911338,205.3542136063507,251.81855389577805,-5.4403901089242765],\"yaxis\":\"y2\",\"type\":\"scatter\",\"uid\":\"33cedb7c-5f52-4da9-bf47-73a199f8aab1\"},{\"mode\":\"lines\",\"name\":\"Duration (100 episode average)\",\"x\":[],\"xaxis\":\"x\",\"y\":[],\"yaxis\":\"y\",\"type\":\"scatter\",\"uid\":\"b689e1f7-c6cd-4926-9640-0f35c6892b54\"},{\"mode\":\"lines\",\"name\":\"Reward (100 episode average)\",\"x\":[],\"xaxis\":\"x2\",\"y\":[],\"yaxis\":\"y2\",\"type\":\"scatter\",\"uid\":\"bff01419-a566-4fcb-be2b-0019dbe5b207\"}],                        {\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Episode Duration\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Episode Reward\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.49,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":30},\"showlegend\":false,\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Training Results\"},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"matches\":\"x2\",\"showticklabels\":false},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.51,1.0],\"title\":{\"text\":\"Duration\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Episode\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.49],\"title\":{\"text\":\"Reward\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cbd222aa-9651-4204-b4d5-4d49ddcef6f4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "DISPLAY_GRAPH_DURING_TRAINING = True\n",
        "\n",
        "num_episodes = 600\n",
        "\n",
        "steps_done = 0\n",
        "steps_at_max_duration = 0\n",
        "\n",
        "for i_episode in trange(num_episodes):\n",
        "    # Initialize the environment and get its state\n",
        "    state, info = env.reset()\n",
        "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    total_reward = 0.0\n",
        "    for t in count():\n",
        "        action = select_action(state, steps_done)\n",
        "        observation, reward, terminated, truncated, _ = env.step(action.item())\n",
        "        total_reward += reward # type: ignore\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        if terminated:\n",
        "            next_state = None\n",
        "        else:\n",
        "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state # type: ignore\n",
        "\n",
        "        # Perform one step of the optimization (on the policy network)\n",
        "        optimize_model()\n",
        "        # Update the target network, copying all weights and biases in DQN\n",
        "        policy_net_update()\n",
        "\n",
        "        steps_done += 1\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "    plot_durations.update(t, total_reward, redisplay=DISPLAY_GRAPH_DURING_TRAINING)\n",
        "\n",
        "    # Early stopping check\n",
        "    # If we're hitting the maximum duration too often, we're probably stuck\n",
        "    if t > MAX_ENV_STEPS*0.99:\n",
        "        steps_at_max_duration += 1\n",
        "        if steps_at_max_duration > 25:\n",
        "            print(f\"Breaking early, episode {i_episode}\")\n",
        "            break\n",
        "    else:\n",
        "        steps_at_max_duration = 0\n",
        "\n",
        "print('Complete')\n",
        "plot_durations.finish(\"Training Results\")\n",
        "plot_durations.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40TWLmakQftm"
      },
      "source": [
        "# Export the training videos\n",
        "\n",
        "We want to be able to see the training we just completed, so lets wrap the videos into a zip file for download from Colab. (Local users can find the videos in the current working directory and skip this step.)\n",
        "\n",
        "Note that if you didn't set up a RecordVideo wrapper on your environment, there won't be any videos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "2xTBcna1Qftm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8f18e4-e435-4a14-b215-667c3b93542e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zipping 136 videos from LunarLander-v3_videos...\n",
            "Videos zipped to LunarLander-v3_videos.zip\n"
          ]
        }
      ],
      "source": [
        "video_paths = list(Path(VIDEOS_DIR).glob(\"*.mp4\"))\n",
        "if not video_paths:\n",
        "    print(f\"No videos found in {VIDEOS_DIR}\")\n",
        "else:\n",
        "    print(f\"Zipping {len(video_paths)} videos from {VIDEOS_DIR}...\")\n",
        "    with ZipFile(f\"{VIDEOS_DIR}.zip\", \"w\") as video_zip:\n",
        "        for video_path in video_paths:\n",
        "            video_zip.write(video_path)\n",
        "\n",
        "    # Try to display a link to the zipped videos\n",
        "    print(f\"Videos zipped to {VIDEOS_DIR}.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eoomx9lKQftn"
      },
      "source": [
        "# Save the model\n",
        "\n",
        "We're going to write the reinforcement learning model to disk so we can use it later.\n",
        "\n",
        "We save it in a pytorch torchscript format, which will allow us to load it and run it even if we change the Python code above. This is useful for deployment, as we can load the model in a C++ application, for example. We can also load the model back into Python and continue training it, or use it to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "My70xO9XQftn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b682362-7dbd-4c28-d7ff-34757d09a036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to LunarLander-v3_dqn.pt\n"
          ]
        }
      ],
      "source": [
        "LANDER_NET_FILE = f\"{GYM_ENV}_dqn.pt\"\n",
        "torch.jit.save(policy_net.cpu(), LANDER_NET_FILE)\n",
        "\n",
        "# Try to display a link to the model file\n",
        "print(f\"Model saved to {LANDER_NET_FILE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ7nakrzQftn"
      },
      "source": [
        "# Evaluate the model\n",
        "\n",
        "We're going to evaluate the model by running it in the environment and seeing how well it performs over a hundred runs. This is evaluation only, so we should be able to run this part faster than the training part from above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "YlUhlkj8Qftn"
      },
      "outputs": [],
      "source": [
        "LANDER_NET_FILE = f\"{GYM_ENV}_dqn.pt\"\n",
        "model = torch.jit.load(LANDER_NET_FILE).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "f05s5L52Qftn"
      },
      "outputs": [],
      "source": [
        "# Unwrap our environment to prevent any weirdness.\n",
        "eval_env = TimeLimit(env.unwrapped, max_episode_steps=750)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "jwfxSjp8Qftn"
      },
      "outputs": [],
      "source": [
        "durations = []\n",
        "# TODO: Track reward for the episodes\n",
        "# Code here\n",
        "episode_rewards = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "VWuFuJwsQftn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63de49e3-c938-4cd8-f4c0-3659cde3041e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:25<00:00,  3.87it/s]\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    EVAL_EPISODES = 100\n",
        "    for _ in trange(EVAL_EPISODES):\n",
        "        state, info = eval_env.reset()\n",
        "        state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "        for t in count():\n",
        "            action = model(state).argmax().item()\n",
        "            observation, reward, terminated, truncated, _ = eval_env.step(action)\n",
        "            # TODO: Track reward for the episodes\n",
        "            # Code here\n",
        "            if t == 0:\n",
        "                total_reward = 0.0\n",
        "            total_reward += reward\n",
        "            if terminated or truncated:\n",
        "                episode_rewards.append(total_reward)\n",
        "                break\n",
        "            # TODO: Track reward for the episodes\n",
        "            # Code here\n",
        "            state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "        durations.append(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnTvQpc0Qfto"
      },
      "source": [
        "# Plot the evaluation results\n",
        "\n",
        "The cartpole assignment is considered solved when the agent can pass all steps in a given episode without the pole falling over. Here, we've limited the evaluation to 750 steps, so we should see over 700 steps on average in our durations histogram below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "0tDSYpOHQfto",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "a533bd80-3b88-4612-9358-a362a3392731"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"034bfd48-84ba-4a98-b124-385fc611258d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"034bfd48-84ba-4a98-b124-385fc611258d\")) {                    Plotly.newPlot(                        \"034bfd48-84ba-4a98-b124-385fc611258d\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ecount=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[251,214,255,228,262,467,235,236,596,240,269,263,221,253,749,272,273,294,246,668,405,306,248,260,242,525,251,306,357,288,238,227,245,250,238,269,267,234,749,749,749,240,379,749,253,224,231,248,749,235,219,478,749,239,749,531,245,266,231,268,291,241,279,451,190,652,257,272,264,451,610,223,212,258,246,289,274,224,224,286,296,396,321,287,268,247,231,258,241,317,255,341,259,575,286,237,288,270,287,145],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Duration\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frequency\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Episode Durations (100 episodes)\"},\"barmode\":\"relative\",\"shapes\":[{\"line\":{\"color\":\"green\",\"dash\":\"dash\"},\"type\":\"line\",\"x0\":331.77,\"x1\":331.77,\"xref\":\"x\",\"y0\":0,\"y1\":1,\"yref\":\"y domain\"}],\"annotations\":[{\"showarrow\":false,\"text\":\"Mean: 331.77\",\"x\":331.77,\"xanchor\":\"left\",\"xref\":\"x\",\"y\":1,\"yanchor\":\"top\",\"yref\":\"y domain\"}],\"margin\":{\"l\":0,\"r\":0,\"t\":30,\"b\":0},\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('034bfd48-84ba-4a98-b124-385fc611258d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean duration: 331.77 steps\n"
          ]
        }
      ],
      "source": [
        "mean_duration = np.mean(durations)\n",
        "fig = px.histogram(x=durations, title=f\"Episode Durations ({len(durations)} episodes)\")\n",
        "fig.add_vline(x = mean_duration, line_dash=\"dash\", line_color=\"green\", annotation_text=f\"Mean: {np.mean(durations):.2f}\", annotation_position=\"top right\")\n",
        "fig.update_layout(xaxis_title=\"Duration\", yaxis_title=\"Frequency\", showlegend=False, margin=dict(l=0, r=0, t=30, b=0))\n",
        "fig.show()\n",
        "print(f\"Mean duration: {mean_duration:.2f} steps\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIWqWEdqQfto"
      },
      "source": [
        "For other gyms, like LunarLander, the environment is considered solved not on duration, but on _reward_. Specifically, for LunarLander, the gym is solved when the agent can achieve an average reward of 200 over 100 episodes. This code doesn't track nor plot the episode reward, but you can easily modify the code to do so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "1rENsfA6Qfto",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "acb7574a-6bc8-4722-8c71-1f3b1e21afd6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"5f07a590-408f-4582-907d-90f53ad4cfe6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5f07a590-408f-4582-907d-90f53ad4cfe6\")) {                    Plotly.newPlot(                        \"5f07a590-408f-4582-907d-90f53ad4cfe6\",                        [{\"nbinsx\":20,\"x\":[259.01501536920864,1.6615985880714277,262.5978169957512,228.6054877375813,241.55312448589126,261.4364610234074,268.48601720023106,240.07118103856715,256.5852184291431,288.10466216610655,254.13901390624437,269.45597429635563,30.154750086634664,247.30993518012625,138.2735611775092,288.89929625214586,241.92776065633853,246.58858340719664,275.4697554934173,183.28740428396398,251.08606482764756,305.3819162007877,265.32016864980534,254.25592052859474,254.19087228724266,278.12261241879264,230.21226766471324,241.8573387880045,247.39026942194243,268.7073866804534,250.29181977083985,278.0475249076369,261.25784883726675,237.9313669517072,235.18875371455167,259.56825873359617,262.4010005286543,261.00349161008376,132.44032004457827,156.52582443964906,148.4430755673244,257.551488302068,255.6185078934506,115.0504506013676,281.4504431352987,235.50416676856003,254.92775856655953,252.58387221277604,148.39531619563735,247.5690160544263,265.9509551613959,226.03630607461588,285.06451057354116,227.04096454183406,160.36144494666982,222.5637674337953,260.4395316481972,245.32632926299982,252.1951667165605,271.189487087066,248.8092168584855,245.85999090163466,264.3094048263029,225.34613837173362,91.86602168610185,271.5237144582198,246.3021550757004,248.58051353164078,251.39279822557046,272.3607704749371,276.0649669337663,207.76092350683925,36.1034797165795,242.66681863765905,233.76581887737734,263.9352067423464,273.6269972894082,255.2748172172942,255.7066470637608,256.9999429623666,232.41227905118114,254.069617853211,270.0553914439255,222.414044409987,256.8876536030731,243.32995039609088,255.90426852357749,267.816191110815,252.89971006520258,238.36817186844195,246.49273476705525,244.08813240963872,253.57830022966135,280.8090469374872,245.24452652780423,253.9033110240009,247.38886750330875,269.7031406723295,283.63185064681045,34.65689477302979],\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"shapes\":[{\"line\":{\"color\":\"red\",\"dash\":\"dash\"},\"type\":\"line\",\"x0\":235.49976630698941,\"x1\":235.49976630698941,\"xref\":\"x\",\"y0\":0,\"y1\":1,\"yref\":\"y domain\"}],\"annotations\":[{\"showarrow\":false,\"text\":\"Mean: 235.50\",\"x\":235.49976630698941,\"xanchor\":\"left\",\"xref\":\"x\",\"y\":1,\"yanchor\":\"top\",\"yref\":\"y domain\"}],\"title\":{\"text\":\"Reward Histogram\"},\"xaxis\":{\"title\":{\"text\":\"Reward\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5f07a590-408f-4582-907d-90f53ad4cfe6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean reward: 235.50\n"
          ]
        }
      ],
      "source": [
        "mean_reward = np.mean(episode_rewards) # Use episode_rewards instead of rewards\n",
        "# Add a histogram of rewards\n",
        "import plotly.graph_objects as go\n",
        "fig = go.Figure(data=[go.Histogram(x=episode_rewards, nbinsx=20)]) # Use episode_rewards instead of rewards\n",
        "fig.add_vline(x=mean_reward, line_dash=\"dash\", line_color=\"red\", annotation_text=f\"Mean: {mean_reward:.2f}\")\n",
        "fig.update_layout(title=\"Reward Histogram\", xaxis_title=\"Reward\", yaxis_title=\"Frequency\")\n",
        "fig.show()\n",
        "print(f\"Mean reward: {mean_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNSHckTJQfto"
      },
      "source": [
        "Remember to submit this notebook and your completed model to the GradeScope autograder."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}